{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3bba2c14",
      "metadata": {
        "id": "3bba2c14"
      },
      "source": [
        "# Sleep Quality Prediction using Machine Learning\n",
        "This notebook trains a classification model to predict sleep quality based on lifestyle and physiological data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea16ad0",
      "metadata": {
        "id": "5ea16ad0"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad623c8",
      "metadata": {
        "id": "fad623c8"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ddf6ce",
      "metadata": {
        "id": "c1ddf6ce"
      },
      "outputs": [],
      "source": [
        "# Dataset: Sleep Health and Lifestyle\n",
        "url = \"https://raw.githubusercontent.com/thiagosnuness/sleep_backend/refs/heads/main/machine_learning/Sleep_health_and_lifestyle_dataset.csv\"\n",
        "df = pd.read_csv(url, keep_default_na=False)\n",
        "\n",
        "# Displaying first rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d71f11",
      "metadata": {
        "id": "f4d71f11"
      },
      "source": [
        "## Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0a9bb3",
      "metadata": {
        "id": "2f0a9bb3"
      },
      "outputs": [],
      "source": [
        "# Mapping categorical variables to numeric\n",
        "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "df['Sleep Disorder'] = df['Sleep Disorder'].map({'None': 0, 'Insomnia': 1, 'Sleep Apnea': 1})\n",
        "\n",
        "# Selecting features and target: numeric and strongly linked to sleep behavior, improving model performance and interpretability.\n",
        "features = ['Age', 'Heart Rate', 'Stress Level', 'Physical Activity Level', 'Sleep Duration']\n",
        "X = df[features]\n",
        "y = df['Sleep Disorder']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a46a67d",
      "metadata": {
        "id": "8a46a67d"
      },
      "source": [
        "## Splitting the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7bd0da",
      "metadata": {
        "id": "4f7bd0da"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)\n",
        "\n",
        "# K-Fold for validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b63037f0",
      "metadata": {
        "id": "b63037f0"
      },
      "source": [
        "## Evaluating Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558283c5",
      "metadata": {
        "id": "558283c5"
      },
      "outputs": [],
      "source": [
        "# Models to compare\n",
        "models = []\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Lists to store results\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Cross-validation\n",
        "for name, model in models:\n",
        "    result = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "    results.append(result)\n",
        "    names.append(name)\n",
        "    print(f\"{name}: Mean Accuracy = {result.mean():.4f} (+/- {result.std():.4f})\")\n",
        "\n",
        "# Creating the boxplot\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "plt.title('Model Comparison')\n",
        "box = plt.boxplot(results, patch_artist=True)\n",
        "best = np.argmax([r.mean() for r in results])\n",
        "[patch.set_facecolor('lightgreen' if i == best else 'lightgray') for i, patch in enumerate(box['boxes'])]\n",
        "plt.xticks(ticks=range(1, len(names)+1), labels=names)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation with Scaled and Normalized Data\n"
      ],
      "metadata": {
        "id": "BrHBl9NtmJLh"
      },
      "id": "BrHBl9NtmJLh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "\n",
        "# Lists to store results\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Define classifiers\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "nb = ('NB', GaussianNB())\n",
        "svm = ('SVM', SVC())\n",
        "\n",
        "# Define scalers\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "minmax_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Pipelines without scaling\n",
        "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
        "pipelines.append(('CART-orig', Pipeline([cart])))\n",
        "pipelines.append(('NB-orig', Pipeline([nb])))\n",
        "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
        "\n",
        "# Pipelines with StandardScaler\n",
        "pipelines.append(('KNN-std', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('CART-std', Pipeline([standard_scaler, cart])))\n",
        "pipelines.append(('NB-std', Pipeline([standard_scaler, nb])))\n",
        "pipelines.append(('SVM-std', Pipeline([standard_scaler, svm])))\n",
        "\n",
        "# Pipelines with MinMaxScaler\n",
        "pipelines.append(('KNN-norm', Pipeline([minmax_scaler, knn])))\n",
        "pipelines.append(('CART-norm', Pipeline([minmax_scaler, cart])))\n",
        "pipelines.append(('NB-norm', Pipeline([minmax_scaler, nb])))\n",
        "pipelines.append(('SVM-norm', Pipeline([minmax_scaler, svm])))\n",
        "\n",
        "# Cross-validation for each pipeline\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    print(f\"{name}: Mean Accuracy = {cv_results.mean():.3f} (+/- {cv_results.std():.3f})\")\n",
        "\n",
        "# Creating the boxplot\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "fig.suptitle('Comparison of Models with and without Scaling')\n",
        "ax = fig.add_subplot(111)\n",
        "box = ax.boxplot(results, patch_artist=True)\n",
        "best = np.argmax([r.mean() for r in results])\n",
        "[patch.set_facecolor('lightgreen' if i == best else 'lightgray') for i, patch in enumerate(box['boxes'])]\n",
        "ax.set_xticklabels(names, rotation=45, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-iBw_n_8mU8Q"
      },
      "id": "-iBw_n_8mU8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "14a611ac",
      "metadata": {
        "id": "14a611ac"
      },
      "source": [
        "## Hyperparameter Tuning with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef3d127",
      "metadata": {
        "id": "4ef3d127"
      },
      "outputs": [],
      "source": [
        "# Pipelines with optional scalers\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Scalers\n",
        "standard_scaler = ('Scaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# KNN\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "pipelines.append(('knn-orig', Pipeline([knn])))\n",
        "pipelines.append(('knn-std', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('knn-norm', Pipeline([min_max_scaler, knn])))\n",
        "\n",
        "# CART (no scaler needed)\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "pipelines.append(('cart', Pipeline([cart])))\n",
        "\n",
        "# SVM\n",
        "svm = ('SVM', SVC())\n",
        "pipelines.append(('svm-std', Pipeline([standard_scaler, svm])))\n",
        "pipelines.append(('svm-norm', Pipeline([min_max_scaler, svm])))\n",
        "\n",
        "# Naive Bayes\n",
        "nb = ('NB', GaussianNB())\n",
        "pipelines.append(('nb-std', Pipeline([standard_scaler, nb])))\n",
        "pipelines.append(('nb-norm', Pipeline([min_max_scaler, nb])))\n",
        "\n",
        "# Hyperparameters for each model\n",
        "param_grids = {\n",
        "    'knn-orig': {'KNN__n_neighbors': list(range(1, 20, 2)), 'KNN__metric': ['euclidean', 'manhattan', 'minkowski']},\n",
        "    'knn-std': {'KNN__n_neighbors': list(range(1, 20, 2)), 'KNN__metric': ['euclidean', 'manhattan', 'minkowski']},\n",
        "    'knn-norm': {'KNN__n_neighbors': list(range(1, 20, 2)), 'KNN__metric': ['euclidean', 'manhattan', 'minkowski']},\n",
        "    'cart': {'CART__max_depth': [None, 5, 10, 15]},\n",
        "    'svm-std': {'SVM__C': [0.1, 1, 10], 'SVM__kernel': ['linear', 'rbf']},\n",
        "    'svm-norm': {'SVM__C': [0.1, 1, 10], 'SVM__kernel': ['linear', 'rbf']},\n",
        "    'nb-std': {},  # Naive Bayes has no hyperparameters to tune\n",
        "    'nb-norm': {},\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "for name, pipeline in pipelines:\n",
        "    param_grid = param_grids[name]\n",
        "    grid = GridSearchCV(pipeline, param_grid=param_grid, scoring='accuracy', cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluation with better parameters\n",
        "    best_model = grid.best_estimator_\n",
        "    cv_scores = cross_val_score(best_model, X_train, y_train, scoring='accuracy', cv=kfold)\n",
        "    results.append(cv_scores)\n",
        "    names.append(name)\n",
        "    print(f\"{name} - Best Score: {grid.best_score_:.4f} using {grid.best_params_}\")\n",
        "\n",
        "# Creating the boxplot\n",
        "fig = plt.figure(figsize=(14, 7))\n",
        "fig.suptitle('Comparison of Models - Hyperparameter Tuning with GridSearchCV')\n",
        "ax = fig.add_subplot(111)\n",
        "box = ax.boxplot(results, patch_artist=True)\n",
        "best = np.argmax([r.mean() for r in results])\n",
        "[patch.set_facecolor('lightgreen' if i == best else 'lightgray') for i, patch in enumerate(box['boxes'])]\n",
        "ax.set_xticklabels(names, rotation=45, ha='right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e80b1086",
      "metadata": {
        "id": "e80b1086"
      },
      "source": [
        "## Final Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4832c6af",
      "metadata": {
        "id": "4832c6af"
      },
      "outputs": [],
      "source": [
        "# Training the best model with full training set\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Use best params from GridSearchCV\n",
        "model = SVC(kernel='rbf', C=10)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Accuracy on test set\n",
        "predictions = model.predict(X_test_scaled)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e796e7ec",
      "metadata": {
        "id": "e796e7ec"
      },
      "source": [
        "## Final Training and Prediction with Full Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab6d04f",
      "metadata": {
        "id": "fab6d04f"
      },
      "outputs": [],
      "source": [
        "# Training the final model with all available data\n",
        "scaler = StandardScaler().fit(X)  # Fit scaler on full dataset\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "# Use best parameters found in GridSearchCV\n",
        "model = SVC(kernel='rbf', C=10)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Simulating 3 new input data ('Age', 'Heart Rate', 'Stress Level', 'Physical Activity Level', 'Sleep Duration')\n",
        "new_data = [\n",
        "    [25, 70, 7, 4, 6.5],\n",
        "    [28, 85, 8, 30, 5.9],\n",
        "    [60, 65, 3, 5, 7.5]\n",
        "]\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "predictions_final = model.predict(new_data_scaled)\n",
        "for sample, pred in zip(new_data, predictions_final):\n",
        "    result = \"Disorder\" if pred == 1 else \"No Disorder\"\n",
        "    print(f\"Input: {sample} => Prediction: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "590a7fc4",
      "metadata": {
        "id": "590a7fc4"
      },
      "source": [
        "## Saving the Model and Scaler using Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b255220e",
      "metadata": {
        "id": "b255220e"
      },
      "outputs": [],
      "source": [
        "# Saving model and scaler\n",
        "with open('sleep_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "with open('sleep_scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Conclusion"
      ],
      "metadata": {
        "id": "Xrt3oF8YcQZW"
      },
      "id": "Xrt3oF8YcQZW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After evaluating multiple classification models — **K-Nearest Neighbors (KNN)**, **Decision Tree (CART)**, **Naive Bayes**, and **Support Vector Machine (SVM)** — under different preprocessing conditions (original data, standardized, and normalized), we performed hyperparameter tuning using `GridSearchCV` to optimize each model.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "- The best model after hyperparameter tuning was:\n",
        "  - **Support Vector Machine (SVM)** with **RBF kernel** and **C=10**\n",
        "  - Achieved a **mean cross-validation accuracy** of **93.31%**\n",
        "  - Achieved a **final test accuracy** of **96%**\n",
        "\n",
        "- Standardization (using `StandardScaler`) significantly improved the performance of SVM and KNN models.\n",
        "\n",
        "**Final Model Selected:**\n",
        "```python\n",
        "model = SVC(kernel='rbf', C=10)\n",
        "```\n",
        "\n",
        "**Dataset Source**  \n",
        "The dataset used in this project was obtained from [Kaggle – Sleep Health and Lifestyle Dataset](https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset)  \n",
        "It contains information about age, heart rate, stress levels, physical activity, sleep duration, and more, allowing the prediction of potential sleep disorders.\n"
      ],
      "metadata": {
        "id": "vR1eoByJcaMc"
      },
      "id": "vR1eoByJcaMc"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}